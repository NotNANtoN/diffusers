{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"src/diffusers/\")\n",
    "from diffusers import StableDiffusionDepth2ImgPipeline, DPMSolverMultistepScheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "\n",
    "model_id = \"stabilityai/stable-diffusion-2-depth\"\n",
    "\n",
    "\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "\n",
    "pipe = StableDiffusionDepth2ImgPipeline.from_pretrained(\n",
    "                        model_id,\n",
    "                        scheduler=scheduler,\n",
    "                        revision=\"fp16\", torch_dtype=torch.bfloat16\n",
    "                    )\n",
    "pipe = pipe.to(\"cuda\")\n",
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "init_image = Image.open(requests.get(url, stream=True).raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Dogs - Stunning painted masterpiece. 4k, HDR\"\n",
    "prompt = \"a photo of an astronaut riding a horse on mars. 4K, HDR\"\n",
    "n_propmt = \"bad, deformed, blurry, ugly, bad anatomy, watermark, pixelated, oversaturated, watermarked\"\n",
    "image = pipe(prompt=prompt, image=init_image,\n",
    "             num_inference_steps=20,\n",
    "             negative_prompt=n_propmt, strength=0.95).images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_map = torch.rand(1, 60, 80) * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.disable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "to_pil = torchvision.transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil(depth_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.unet = torch.compile(pipe.unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image = pipe(prompt=start_p, \n",
    "             image=init_image,\n",
    "             num_inference_steps=30,\n",
    "             #depth_map=depth_map,\n",
    "             negative_prompt=n_propmt, strength=0.9).images[0]\n",
    "start_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_p = \"A sad woman is dropping her head\"\n",
    "prompt = \"A happy woman smiling and raising her hands\"\n",
    "start_image = pipe(prompt=start_p, \n",
    "             image=init_image,\n",
    "             num_inference_steps=30,\n",
    "             #depth_map=depth_map,\n",
    "             negative_prompt=n_propmt, strength=0.9).images[0]\n",
    "last_img = start_image\n",
    "imgs = []\n",
    "for _ in range(10):\n",
    "    last_img = pipe(prompt=prompt, \n",
    "             image=last_img,\n",
    "             num_inference_steps=12,\n",
    "             negative_prompt=n_propmt, strength=0.6).images[0]\n",
    "    imgs.append(last_img)\n",
    "    last_img.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StableDiffusionDepth2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"src/diffusers/\")\n",
    "from diffusers import StableDiffusionPipeline, EulerDiscreteScheduler, LMSDiscreteScheduler, DPMSolverMultistepScheduler, PNDMScheduler\n",
    "import torch\n",
    "\n",
    "#model_id = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "model_id = \"../mus2vid/models/stable-diffusion-v1-5\"\n",
    "\n",
    "\n",
    "scheduler = DPMSolverMultistepScheduler.from_pretrained(model_id, subfolder=\"scheduler\")\n",
    "#schedulers = [LMSDiscreteScheduler, DPMSolverMultistepScheduler, PNDMScheduler]\n",
    "#scheduler = schedulers[1](\n",
    "#    beta_start=0.00085, \n",
    "#    beta_end=0.012, \n",
    "#    beta_schedule=\"scaled_linear\"\n",
    "#)\n",
    "\n",
    "#pipe = StableDiffusionPipeline.from_pretrained(model_id, scheduler=scheduler,\n",
    "#                                               local_files_only=True,\n",
    "#                                               revision=\"fp16\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        scheduler=scheduler,\n",
    "        use_auth_token=\"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\", # TODO remove hard-coded token\n",
    "        safety_checker=None,\n",
    "        revision=\"fp16\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    ).to(\"cuda\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "#pipe.enable_xformers_memory_efficient_attention()\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " #cfg[\"postfix\"] = \"Stunning moody, hardcore, heavy, imagery masterpiece by Anastasiya Markovich and Zdislaw Beksinski\"\n",
    "            #cfg[\"postfix\"] = \"Masterpiece imagery, collaboration by Paris Barclay and David G\"\n",
    "            #cfg[\"postfix\"] = \"Masterpiece imagery, collaboration by Chris Robinson and Director X\"\n",
    "            #cfg[\"postfix\"] = \"Masterpiece imagery, collaboration by Benny Boom and Hype Williams\"\n",
    "            #cfg[\"postfix\"] = \"Masterpiece imagery, collaboration by Cole Bennett and Dave Meyers\"\n",
    "            cfg[\"postfix\"] = \"Masterpiece imagery, in the style of Gorillaz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip_hop_music_vid_producers = [\"\", \"Paris Barclay\",  \"David G\", \n",
    "                                       \"Chris Robinson\", \"Director X\",\n",
    "                                       \"Benny Boom\", \"Hype Williams\",\n",
    "                                       \"Cole Bennett\", \"Dave Meyers\", \"Gorillaz\"]\n",
    "clip_known_hip_hop_music_vid_producers = [\"\", \"Paris Barclay\", \"Director X\", \"Hype Williams\", \"Dave Meyers\", \"Gorillaz\", \"Beksinski\"]\n",
    "\n",
    "imgs = []\n",
    "for producer in clip_known_hip_hop_music_vid_producers:\n",
    "    prompt = f\"Masterpiece music video scene, produced by {producer}. 4K, HDR\"\n",
    "\n",
    "    image = pipe(prompt, width=512, height=768, output_type=\"pil\", \n",
    "                 guidance_scale=10,\n",
    "                 seed=2).images[0]\n",
    "    imgs.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Masterpiece imagery, by Cole Bennett and Dave Meyers\"\n",
    "\n",
    "image = pipe(prompt, width=512, height=512, output_type=\"pil\", seed=1).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Masterpiece imagery, in the style of Gorillaz\"\n",
    "\n",
    "image = pipe(prompt, width=512, height=512, output_type=\"pil\", seed=1).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Masterpiece music video, in the style of Gorillaz\"\n",
    "\n",
    "image = pipe(prompt, width=512, height=512, output_type=\"pil\", seed=1).images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.vae = torch.compile(pipe.vae, fullgraph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe.unet = torch.compile(pipe.unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(a):\n",
    "    return (a - a.min()) / (a.max() - a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The death star - Stunning artwork by John Berkey. 4K, HDR\"\n",
    "\n",
    "image = pipe(prompt, width=512, height=512, output_type=\"pil\").images[0]\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(prompt, seed=2, width=512, height=512, output_type=\"pil\").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"red\"\n",
    "image = pipe(prompt, seed=2, width=512, height=512, output_type=\"pil\").images[0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(prompt, seed=2, width=512, height=512).images[0]  \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"src/diffusers/\")\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import torch\n",
    "\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\"../mus2vid/models/stable-diffusion-v1-5\")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a photo of an astronaut riding a horse on mars\"\n",
    "image = pipe(prompt).images[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"chicken cheeese\").images[0]  \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = pipe(\"camouflage person chicken cheeese\").images[0]  \n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"src/\")\n",
    "sys.path.append(\"src/diffusers/\")\n",
    "\n",
    "# make sure you're logged in with `huggingface-cli login`\n",
    "import torch\n",
    "from torch import autocast\n",
    "from diffusers import StableDiffusionPipeline, LMSDiscreteScheduler, DPMSolverMultistepScheduler, PNDMScheduler\n",
    "import numpy as np\n",
    "import imageio\n",
    "import torchvision.transforms as T\n",
    "\n",
    "to_pil = T.ToPILImage()\n",
    "\n",
    "os.makedirs(\"stable_outs\", exist_ok=True)\n",
    "schedulers = [LMSDiscreteScheduler, DPMSolverMultistepScheduler, PNDMScheduler]\n",
    "lms = schedulers[1](\n",
    "    beta_start=0.00085, \n",
    "    beta_end=0.012, \n",
    "    beta_schedule=\"scaled_linear\"\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    #\"../mus2vid/models/stable-diffusion-v1-5\",#\"runwayml/stable-diffusion-v1-5\", \n",
    "    \"examples/text_to_image/sdv1-5-var-aspect-4-1-1-1\",\n",
    "    scheduler=lms,\n",
    "    use_auth_token=True,\n",
    "    safety_checker=None,\n",
    "    revision=\"fp16\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "#pipe.enable_attention_slicing(2)\n",
    "\n",
    "def pathify_prompt(prompt):\n",
    "    return prompt.replace(\" \", \"_\").replace(\",\", \"\")\n",
    "\n",
    "def save_image(image, prompt):\n",
    "    path = f\"stable_outs/{pathify_prompt(prompt)}.jpg\"\n",
    "    image.save(path, quality=95, subsample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_cv2(sample: np.ndarray) -> torch.Tensor:\n",
    "    sample = ((sample.astype(float) / 255.0) * 2) - 1\n",
    "    sample = sample[None].transpose(0, 3, 1, 2).astype(np.float16)\n",
    "    sample = torch.from_numpy(sample).float().clip(0, 1)\n",
    "    return sample\n",
    "\n",
    "\n",
    "def sample_to_cv2(sample: torch.Tensor) -> np.ndarray:\n",
    "    from einops import rearrange\n",
    "    sample_f32 = rearrange(sample.squeeze().cpu().numpy(), \"c h w -> h w c\").astype(np.float32)\n",
    "    sample_f32 = ((sample_f32 * 0.5) + 0.5).clip(0, 1)\n",
    "    sample_int8 = (sample_f32 * 255).astype(np.uint8)\n",
    "    return sample_int8\n",
    "\n",
    "\n",
    "def maintain_colors(prev_img, color_match_sample, hsv=False, lab=False, pil_input=False):\n",
    "    from skimage.exposure import match_histograms\n",
    "    import cv2\n",
    "    if pil_input:\n",
    "        prev_img = torch.tensor(np.array(prev_img)).permute(2, 0, 1).unsqueeze(0) / 255\n",
    "        color_match_sample = torch.tensor(np.array(color_match_sample)).permute(2, 0, 1).unsqueeze(0) / 255\n",
    "    prev_img = sample_to_cv2(prev_img)\n",
    "    color_match_sample = sample_to_cv2(color_match_sample)\n",
    "    if hsv:\n",
    "        prev_img_hsv = cv2.cvtColor(prev_img, cv2.COLOR_RGB2HSV)\n",
    "        color_match_hsv = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2HSV)\n",
    "        matched_hsv = match_histograms(prev_img_hsv, color_match_hsv, multichannel=True)\n",
    "        img = cv2.cvtColor(matched_hsv, cv2.COLOR_HSV2RGB)\n",
    "    elif lab:\n",
    "        prev_img_lab = cv2.cvtColor(prev_img, cv2.COLOR_RGB2LAB)\n",
    "        color_match_lab = cv2.cvtColor(color_match_sample, cv2.COLOR_RGB2LAB)\n",
    "        matched_lab = match_histograms(prev_img_lab, color_match_lab, multichannel=True)\n",
    "        img = cv2.cvtColor(matched_lab, cv2.COLOR_LAB2RGB)    \n",
    "    else:\n",
    "        img = match_histograms(prev_img, color_match_sample, multichannel=True)\n",
    "    img = sample_from_cv2(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"An ancient dream starts to calm down. It is quiet and peaceful. A stunning painting by Anton Wiehe and Salvador Dali\"\n",
    "\n",
    "prompt = \"A portrait photo of a european male language student, age 50, 4K, stunning lighting, beautiful face\"\n",
    "\n",
    "#width = 64 * 12\n",
    "#height = 64 * 8\n",
    "# max - 20 or 21 * 64 on both sides\n",
    "#width = 14 * 64\n",
    "#height = 7 * 64\n",
    "#width, height = 512, 768\n",
    "width, height = 1024, 512\n",
    "\n",
    "\n",
    "print(width, height)\n",
    "\n",
    "out = pipe(prompt, output_type=\"latent\",  num_inference_steps=30,\n",
    "                   guidance_scale=10, seed=1011,\n",
    "                    width=width, height=height,\n",
    "                    negative_prompt=\"watermarked, hands, blurry, low quality, disfigured face, blurry eyes\",\n",
    "          )\n",
    "alien_latent = out[\"images\"][0]     \n",
    "with torch.inference_mode():\n",
    "    alien_image = pipe.decode_image(alien_latent.unsqueeze(0), output_type=\"torch\", device=\"cuda\")[0]\n",
    "to_pil(alien_image)\n",
    "#alien_latent.mean(), alien_latent.std()#, ContrastLoss()(alien_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prompt = \"An ancient dream starts to calm down. It is quiet and peaceful. A stunning painting by Anton Wiehe and Salvador Dali\"\n",
    "\n",
    "prompt = \"A portrait photo of a european male language student, age 50, 4K, stunning lighting, beautiful face\"\n",
    "\n",
    "#width = 64 * 12\n",
    "#height = 64 * 8\n",
    "# max - 20 or 21 * 64 on both sides\n",
    "#width = 14 * 64\n",
    "#height = 7 * 64\n",
    "#width, height = 512, 768\n",
    "width, height = 1024, 512\n",
    "\n",
    "\n",
    "print(width, height)\n",
    "\n",
    "out = pipe(prompt, output_type=\"latent\",  num_inference_steps=30,\n",
    "                   guidance_scale=10, seed=1011,\n",
    "                    width=width, height=height,\n",
    "                    negative_prompt=\"watermarked, hands, blurry, low quality, disfigured face, blurry eyes\",\n",
    "          )\n",
    "alien_latent = out[\"images\"][0]     \n",
    "with torch.inference_mode():\n",
    "    alien_image = pipe.decode_image(alien_latent.unsqueeze(0), output_type=\"torch\", device=\"cuda\")[0]\n",
    "to_pil(alien_image)\n",
    "#alien_latent.mean(), alien_latent.std()#, ContrastLoss()(alien_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"accidentally wes anderson award - winning photograph of boston dynamics robots on a lunch break eating pizza and drinking coffee, epic calmness scene, 4 k, detailed, art by greg rutkowsky, trending on artstation, cinematic lighting, filmic grain, golden hour, detailed, 4 k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \" painted portrait of rugged zeus, god of thunder, greek god, white hair, masculine, mature, handsome, upper body, flowy robe, muscular, hairy torso, fantasy, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by gaston bussiere and alphonse mucha \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(#p,\n",
    "           \"A photo of pikachu. Photorealistic masterpiece\",\n",
    "            output_type=\"pil\",  num_inference_steps=30,\n",
    "                   guidance_scale=10, seed=101,\n",
    "                    width=512, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(#p,\n",
    "           \"A photo of pikachu. Photorealistic masterpiece\",\n",
    "            output_type=\"pil\",  num_inference_steps=30,\n",
    "                   guidance_scale=10, seed=101,\n",
    "                    width=512, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(#p,\n",
    "           \"Rise and shine - Zeus painting. Photorealistic masterpiece\",\n",
    "            output_type=\"pil\",  num_inference_steps=100,\n",
    "                   guidance_scale=10, seed=10111,\n",
    "                    width=256, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(#p,\n",
    "           \"Rise and shine - Zeus painting. Photorealistic masterpiece\",\n",
    "            output_type=\"pil\",  num_inference_steps=100,\n",
    "                   guidance_scale=10, seed=10111,\n",
    "                    width=256, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(#p,\n",
    "           \"Rise and shine - Zeus painting. Photorealistic masterpiece\",\n",
    "            output_type=\"pil\",  num_inference_steps=30,\n",
    "                   guidance_scale=10, seed=10111,\n",
    "                    width=256, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(p, output_type=\"pil\",  num_inference_steps=20,\n",
    "                   guidance_scale=10, seed=11,\n",
    "                    width=512, height=512,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Pikachu\",\n",
    "           output_type=\"pil\",  num_inference_steps=20,\n",
    "                   guidance_scale=10, seed=11,\n",
    "                    width=768, height=576,\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.WARNING, format='%(message)s')\n",
    "\n",
    "width = 768\n",
    "height = 576\n",
    "\n",
    "pipe.compile_models(f\"vert_{width}x{height}\", width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put channels last\n",
    "#pipe.unet.to(memory_format=torch.channels_last)  # in-place operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"painted portrait of rugged zeus, god of thunder, greek god, white hair, masculine, mature, handsome, upper body, flowy robe, muscular, hairy torso, fantasy, intricate, elegant, highly detailed, digital painting, artstation, concept art, smooth, sharp focus, illustration, art by gaston bussiere and alphonse mucha \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = \"accidentally wes anderson award - winning photograph of boston dynamics robots on a lunch break eating pizza and drinking coffee, epic calmness scene, 4 k, detailed, art by greg rutkowsky, trending on artstation, cinematic lighting, filmic grain, golden hour, detailed, 4 k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horrors = \"cosmic horrors on my mcdonald's burger, close up of mcdonald's burger, by zdzislaw beksinski, by dariusz zawadzki, by john jude palencar, gothic, surrealism, cosmic horror, lovecraftian, cold hue's, warm tone gradient background, concept art, scene in dining room, beautiful composition \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliced model was at 5.0 GB VRAM (without deleting vae decoder) and at 55 it/s\n",
    "# non-sliced model was at 5.2 GB VRAM (without deleting vae decoder) and at 72 it/s\n",
    "# 768x768 model at 5.5 GB VRAM with 28 it/s\n",
    "# 1024x1024 model at 6.2 GB VRAM with 12 it/s\n",
    "# 1920 x 1088 model at 9.6 GB VRAM with 3.7 it/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 768 #1920 // 2\n",
    "height = 576 #1088 // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "img = Image.open(\"HD_jesus.jpg\")\n",
    "img = img.resize((width, height))\n",
    "img = ImageOps.contain(img, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(horrors,\n",
    "            guidance_scale=10, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(horrors,\n",
    "            guidance_scale=12, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.6,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(horrors,\n",
    "            guidance_scale=10, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Jesus snorting cocaine. Photorealistic Masterpiece\",\n",
    "            guidance_scale=10, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Jesus snorting cocaine. Photorealistic Masterpiece\",\n",
    "            guidance_scale=10, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Jesus snorting cocaine. Photorealistic Masterpiece\",\n",
    "            guidance_scale=10, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.95,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Jesus snorting cocaine. Photorealistic Masterpiece\",\n",
    "            guidance_scale=20, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            #start_img=img,\n",
    "            #img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(p,\n",
    "            guidance_scale=20, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=40,\n",
    "            #start_img=img,\n",
    "            #img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(p,\n",
    "            guidance_scale=20, seed=101010,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=40,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(\"Jesus as cola man, the god of all coke\",\n",
    "            guidance_scale=13, seed=1010101,\n",
    "            width=width, height=height,\n",
    "            num_inference_steps=30,\n",
    "            start_img=img,\n",
    "            img2img_strength=0.8,\n",
    "            negative_prompt=\"pixelated, jpg-compression\",\n",
    "           )[0][0]\n",
    "#out.save(\"test.png\")\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.save(\"test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(p,\n",
    "            guidance_scale=20, seed=11,\n",
    "            width=512, height=512,\n",
    "            num_inference_steps=30,\n",
    "            #negative_prompt=\"grid, messy background, text, ugly\",\n",
    "           )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = pipe(p,\n",
    "            output_type=\"pil\",  num_inference_steps=40,\n",
    "                    guidance_scale=10, seed=10101003,\n",
    "                    width=1024, height=768,\n",
    "                    negative_prompt=\"low resolution\",\n",
    "          )[0][0]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.to(\"cpu\")\n",
    "vae = pipe.vae.cuda()\n",
    "#pil_imgs = imagine.decode_image(latents, output_type=\"pil\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def decode(batch_size=1):\n",
    "    rand_latent = torch.randn(batch_size, 4, 64, 64).cuda()\n",
    "    pipe.vae.decode(rand_latent)\n",
    "    #out = pipe.decode_image(rand_latent, output_type=\"pil\", device=\"cuda\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with autocast(\"cuda\"):\n",
    "#        with torch.inference_mode():\n",
    "#            %timeit decode(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"Plazma. Stunning logo, 4K\", \"Plazma Punk. Stunning anarchist logo in the style of Beksinski, Dali, Monet. 4K\",\n",
    "          \"Punk fusing into plazma. Stunning logo in the style of Dali, Beksinski\"]\n",
    "for prompt in prompts:\n",
    "    with autocast(\"cuda\"):\n",
    "        out = pipe(prompt, output_type=\"latent\",  num_inference_steps=50,\n",
    "                           guidance_scale=12, seed=1,\n",
    "                            width=512, height=512,\n",
    "                  )\n",
    "        alien_latent = out[\"sample\"][0]     \n",
    "        with torch.inference_mode():\n",
    "            alien_image = pipe.decode_image(alien_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "    to_pil(alien_image).show()\n",
    "    alien_latent.mean(), alien_latent.std()#, ContrastLoss()(alien_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alien_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        latents = alien_latent.unsqueeze(0) / 0.18215\n",
    "        image = pipe.vae.decode(latents.to(\"cuda\"\n",
    "                                          ))[\"sample\"]\n",
    "        image = (image / 2 + 0.5).clamp(0, 1)\n",
    "        image = image.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_pil(image.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "680 / 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"An ancient dream starts to calm down. It is quiet and peaceful. A stunning painting by Anton Wiehe and Salvador Dali\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=50,\n",
    "                       guidance_scale=7, seed=1,\n",
    "                        width=512, height=512,\n",
    "              )\n",
    "    alien_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        alien_image = pipe.decode_image(alien_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(alien_image).show()\n",
    "alien_latent.mean(), alien_latent.std()#, ContrastLoss()(alien_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The alien (4K resolution)\"#. Contest-winning Masterpiece (4K)\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=20,\n",
    "                       guidance_scale=12, seed=1,\n",
    "                        width=512, height=512,\n",
    "              )\n",
    "    alien_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        alien_image = pipe.decode_image(alien_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(alien_image).show()\n",
    "alien_latent.mean(), alien_latent.std()#, ContrastLoss()(alien_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "from diffusers.callbacks import create_callbacks, ContrastLoss\n",
    "\n",
    "callbacks = create_callbacks(use_lpips=True, lpips_image=alien_image, \n",
    "                             lpips_lr=0, lpips_frequency=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=30,\n",
    "                       guidance_scale=7, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                        start_img=alien_image,\n",
    "                        img2img_strength=0.7,\n",
    "                       #noise_steps=900,\n",
    "                       #t_start=900,\n",
    "              )\n",
    "    masterpiece_latent = out[\"images\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=30,\n",
    "                       guidance_scale=7, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                        start_img=alien_image,\n",
    "                        img2img_strength=0.6,\n",
    "                       #noise_steps=900,\n",
    "                       #t_start=900,\n",
    "              )\n",
    "    masterpiece_latent = out[\"images\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=7, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                        start_img=alien_image,\n",
    "                        img2img_strength=1.0,\n",
    "                       #noise_steps=900,\n",
    "                       #t_start=900,\n",
    "              )\n",
    "    masterpiece_latent = out[\"images\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=30,\n",
    "                       guidance_scale=7, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        start_img=alien_image,\n",
    "                        img2img_strength=0.1,\n",
    "                  \n",
    "              )\n",
    "    masterpiece_latent = out[\"images\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=1000,\n",
    "                       guidance_scale=12, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                        start_img=alien_image,\n",
    "                        #img2img_strength=0.6,\n",
    "                       noise_steps=900,\n",
    "                       #t_start=900,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std(), ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler.timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler.sigmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2img_strength = 0.8\n",
    "num_inference_steps = 50\n",
    "\n",
    "batch_size = 1\n",
    "offset = 0\n",
    "num_inference_steps = int(np.ceil(num_inference_steps / img2img_strength))\n",
    "# set schedule again according to updated steps\n",
    "pipe.scheduler.set_timesteps(num_inference_steps)\n",
    "# now we calculate how many skeps are skipped (t_start) and at what point the noise is initialized (init_timestep)\n",
    "init_timestep = int(num_inference_steps * img2img_strength) + offset\n",
    "t_start = num_inference_steps - init_timestep + offset\n",
    "#print(\"init_timestep:\", init_timestep, \"t_start: \", t_start)\n",
    "timesteps = int(pipe.scheduler.timesteps[t_start])\n",
    "timesteps = torch.tensor([timesteps] * batch_size, dtype=torch.long, device=pipe.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timestep = int(pipe.scheduler.timesteps[-t_start])\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        sigma = pipe.scheduler.sigmas[t_start]\n",
    "        print(sigma, ((sigma**2 + 1) ** 0.5))\n",
    "        \n",
    "        image_embed = pipe.encode_image(alien_image)\n",
    "\n",
    "        noise = torch.randn_like(image_embed)\n",
    "        image_embed = pipe.scheduler.add_noise(image_embed, noise, timesteps)\n",
    "        \n",
    "        # multiply by sigma\n",
    "        #image_embed = image_embed * sigma\n",
    "                \n",
    "        image_embed = image_embed / ((sigma**2 + 1) ** 0.5)\n",
    "        \n",
    "        out = pipe.decode_image(image_embed)[0]\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = 50\n",
    "\n",
    "timestep = int(pipe.scheduler.timesteps[t_start])\n",
    "print(timestep)\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        sigma = pipe.scheduler.sigmas[t_start]\n",
    "        print(sigma, ((sigma**2 + 1) ** 0.5))\n",
    "        \n",
    "        image_embed = pipe.encode_image(alien_image)\n",
    "\n",
    "        noise = torch.randn_like(image_embed)\n",
    "        image_embed = pipe.scheduler.add_noise(image_embed, noise, timestep)\n",
    "        \n",
    "        \n",
    "        # multiply by sigma\n",
    "        image_embed = image_embed * ((sigma**2 + 1) ** 0.5)\n",
    "        \n",
    "        #\n",
    "        image_embed = image_embed / ((sigma**2 + 1) ** 0.5)\n",
    "        \n",
    "        out = pipe.decode_image(image_embed)[0]\n",
    "out.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=22,\n",
    "                       guidance_scale=12, seed=10,\n",
    "                        width=512, height=512,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=50,\n",
    "                       guidance_scale=12, seed=10,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                        start_img=alien_image,\n",
    "                        img2img_strength=0.9,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std(), ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=20,\n",
    "                       guidance_scale=12, seed=20,\n",
    "                        width=512, height=512,\n",
    "                        loss_callbacks=callbacks,\n",
    "                       start_img=alien_image,\n",
    "                       img2img_strength=0.8,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std(), ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=20,\n",
    "                       guidance_scale=12, seed=1,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                       start_img=alien_image,\n",
    "                       img2img_strength=0.8,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std(), ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"A dodo bird in the forest. 4K nature photography\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=200,\n",
    "                       guidance_scale=12, seed=1,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,\n",
    "                       start_img=alien_image,\n",
    "                       img2img_strength=0.4,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std(), ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "p = plt.hist(masterpiece_latent.cpu().flatten().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness. It feels happy\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=10,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness. Happy\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness.\"\n",
    "prompt_2 = \"It feels happy\"\n",
    "\n",
    "embed = torch.lerp(pipe.embed_prompts([prompt]), pipe.embed_prompts([prompt_2]), 0.1)\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness.\"\n",
    "prompt_2 = \"happy\"\n",
    "\n",
    "embed = torch.lerp(pipe.embed_prompts([prompt]), pipe.embed_prompts([prompt_2]), 0.2)\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness.\"\n",
    "prompt_2 = \"Happy\"\n",
    "\n",
    "embed = torch.lerp(pipe.embed_prompts([prompt]), pipe.embed_prompts([prompt_2]), 0.5)\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../mus2vid\")\n",
    "from mus2vid.math_utils import slerp, norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slerp_latent(a, b, frac):\n",
    "    # only works on single latents atm\n",
    "    a = a.squeeze()\n",
    "    b = b.squeeze()\n",
    "    assert a.ndim == 2\n",
    "    # if we do slerping directly we apply it to all tokens. Instead, apply slerp to each token individually\n",
    "    slerped = [a[0].unsqueeze(0)]\n",
    "    for i in range(1, len(a)):\n",
    "        slerped_token = slerp(a[i].unsqueeze(0), b[i].unsqueeze(0), frac)\n",
    "        slerped.append(slerped_token)\n",
    "    return torch.cat(slerped).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"There is a sound of thunder echoing through the quiet darkness.\"\n",
    "prompt_2 = \"Happy\"\n",
    "\n",
    "embed_1 = pipe.embed_prompts([prompt])\n",
    "embed_2 = pipe.embed_prompts([prompt_2])\n",
    "\n",
    "embed = slerp_latent(embed_1, embed_2, 0.5)\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "               num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=1,\n",
    "                        width=512, height=512,\n",
    "                       #loss_callbacks=callbacks,\n",
    "              )\n",
    "    ass_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image).show()\n",
    "ass_latent.mean(), ass_latent.std()#, ContrastLoss()(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    with autocast(\"cuda\"):\n",
    "        embed_1 = pipe.embed_prompts([prompt])\n",
    "        embed_2 = pipe.embed_prompts([prompt_2])\n",
    "        embed = torch.lerp(embed_1, embed_2, 0.3)\n",
    "        #embed[:, 2, :] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Award-winning photo\"\n",
    "prompt_2 =  \"Award-winning photo. It feels happy\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    with autocast(\"cuda\"):\n",
    "        for w in torch.linspace(0, 1, 10).cuda():\n",
    "            embed_1 = pipe.embed_prompts([prompt])\n",
    "            embed_2 = pipe.embed_prompts([prompt_2])\n",
    "            embed = torch.lerp(embed_1, embed_2, w)\n",
    "\n",
    "            out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "                       num_inference_steps=50,\n",
    "                               guidance_scale=15, seed=1,\n",
    "                                width=512, height=512,\n",
    "                               #loss_callbacks=callbacks,\n",
    "                      )\n",
    "            ass_latent = out[\"sample\"][0]     \n",
    "\n",
    "            fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "            to_pil(fairy_image).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Award-winning photo\"\n",
    "prompt_2 =  \"Sad. Award-winning photo\"\n",
    "\n",
    "with torch.inference_mode():\n",
    "    with autocast(\"cuda\"):\n",
    "        for w in torch.linspace(0, 1, 10).cuda():\n",
    "            embed_1 = pipe.embed_prompts([prompt])\n",
    "            embed_2 = pipe.embed_prompts([prompt_2])\n",
    "            embed = torch.lerp(embed_1, embed_2, w)\n",
    "\n",
    "            out = pipe(text_embeddings=embed, output_type=\"latent\",  \n",
    "                       num_inference_steps=50,\n",
    "                               guidance_scale=15, seed=1,\n",
    "                                width=512, height=512,\n",
    "                               #loss_callbacks=callbacks,\n",
    "                      )\n",
    "            ass_latent = out[\"sample\"][0]     \n",
    "\n",
    "            fairy_image = pipe.decode_image(ass_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "            to_pil(fairy_image).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runnb MusToVi.ipynb net=stable_diffusion do_create_gpt_cluster_stories=1 lat_diff_iterate_on_image=1 postfix=\" Masterpiece artwork by Anton Wiehe\" lat_diff_img2img_strength=0.75 gpu=0 sub_steps=100 num_noise=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterpiece_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate using slerp\n",
    "def slerp(low, high, val):\n",
    "    low_norm = low / torch.norm(low, dim=1, keepdim=True)\n",
    "    high_norm = high / torch.norm(high, dim=1, keepdim=True)\n",
    "    epsilon = 1e-7\n",
    "    omega = (low_norm * high_norm).sum(1)\n",
    "    omega = torch.acos(torch.clamp(omega, -1 + epsilon, 1 - epsilon))\n",
    "    so = torch.sin(omega)\n",
    "    res = (torch.sin((1.0 - val) * omega) / so).unsqueeze(1) * low + (torch.sin(val * omega) / so).unsqueeze(1) * high\n",
    "    return res\n",
    "\n",
    "steps = 10\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        for frac in np.linspace(0, 1, steps):\n",
    "            interp_latent = slerp(masterpiece_latent, ass_latent, frac)\n",
    "            pipe.decode_image(interp_latent.unsqueeze(0))[0].show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put interpolations next to each other and make gif!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My ashes befell the ground and became the fundament of a new society. Award-winning photography\"#, shot on Canon EOS R6\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\",  num_inference_steps=50,\n",
    "                       guidance_scale=15, seed=6,\n",
    "                        width=512, height=512,\n",
    "                        #loss_callbacks=callbacks,  \n",
    "                      # start_img=fairy_image.float(),\n",
    "                       #img2img_strength=0.7,\n",
    "              )\n",
    "    masterpiece_latent = out[\"sample\"][0]     \n",
    "    with torch.inference_mode():\n",
    "        reg_img = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(reg_img).show()\n",
    "masterpiece_latent.mean(), masterpiece_latent.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"My ashes befell the ground and became the fundament of a new society. Masterpiece by Monet and Satan\"\n",
    "\n",
    "reg_img_2 = reg_img\n",
    "\n",
    "for i in range(100):\n",
    "    if i == 5:\n",
    "        prompt = \"My ashes befell the ground and became the fundament of a new society. Masterpiece by Monet. Rainbows everywhere!\"\n",
    "\n",
    "    with autocast(\"cuda\"):\n",
    "        out = pipe(prompt, output_type=\"latent\",  num_inference_steps=1000,\n",
    "                           guidance_scale=12, seed=i * 10,\n",
    "                            width=512, height=512,\n",
    "                            #loss_callbacks=callbacks,  \n",
    "                           start_img=reg_img_2.float(),\n",
    "                           #img2img_strength=0.55,\n",
    "                           noise_steps=20,\n",
    "                           t_start=980,\n",
    "                  )\n",
    "        masterpiece_latent = out[\"sample\"][0]   \n",
    "        last = reg_img_2\n",
    "        with torch.inference_mode():\n",
    "            reg_img_2 = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0].float()\n",
    "        #reg_img_2 = maintain_colors(reg_img_2, last, lab=1, pil_input=0, hsv=0)\n",
    "        \n",
    "    to_pil(reg_img_2.squeeze()).show()\n",
    "    print(masterpiece_latent.mean(), masterpiece_latent.std())#, ContrastLoss()(reg_img_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "import torchvision.transforms as T\n",
    "\n",
    "to_pil = T.ToPILImage()\n",
    "prompt = \"A fairy is flying with her beautiful wings. Digital Masterpiece\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\", use_safety=False,\n",
    "                        num_inference_steps=10, eta=0.75, \n",
    "                       guidance_scale=12, seed=0,\n",
    "                        width=512, height=512, start_img=None,\n",
    "                        )\n",
    "    masterpiece_latent = out[\"sample\"][0] \n",
    "    masterpiece_latent_transition = out[\"latents\"]\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        fairy_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")[0]\n",
    "to_pil(fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterpiece_latent.mean(), masterpiece_latent.std(), masterpiece_latent.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_latent = masterpiece_latent.unsqueeze(0)\n",
    "std = normed_latent.abs().std()\n",
    "mean = normed_latent.abs().mean()\n",
    "normed_latent = (normed_latent - mean) / std\n",
    "with torch.no_grad():\n",
    "    with autocast(\"cuda\"):\n",
    "        decoded = pipe.decode_image(normed_latent)[0]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lpips_callback[\"loss_function\"](fairy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "prompt = \"A cat eating a burger\"\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\", use_safety=False,\n",
    "                        num_inference_steps=20, eta=0.75, \n",
    "                       guidance_scale=12, seed=0,\n",
    "                        width=512, height=512, \n",
    "                       start_img=fairy_image.float(),\n",
    "                       noise_strength_before_encode=0.015,\n",
    "                       img2img_strength=0.6,\n",
    "                       loss_callbacks=callbacks,\n",
    "                        )\n",
    "    masterpiece_latent = out[\"sample\"][0] \n",
    "    masterpiece_latent_transition = out[\"latents\"]\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        masterpiece_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"pil\")[0]\n",
    "masterpiece_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "prompt = \"A cat eating a burger\"\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\", use_safety=False,\n",
    "                        num_inference_steps=20, eta=0.75, \n",
    "                       guidance_scale=12, seed=0,\n",
    "                        width=512, height=512, \n",
    "                       start_img=fairy_image.float(),\n",
    "                       noise_strength_before_encode=0.015,\n",
    "                       img2img_strength=0.8,\n",
    "                       #loss_callbacks=callbacks,\n",
    "                        )\n",
    "    masterpiece_latent = out[\"sample\"][0] \n",
    "    masterpiece_latent_transition = out[\"latents\"]\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        masterpiece_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"pil\")[0]\n",
    "masterpiece_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "prompt = \"Charizard Masterpiece by RJ Palmer\"\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\", use_safety=False,\n",
    "                        num_inference_steps=50, eta=0.75, \n",
    "                       guidance_scale=12, seed=0,\n",
    "                        width=512, height=512, start_img=None,\n",
    "                       #loss_callbacks=callbacks,\n",
    "                        )\n",
    "    masterpiece_latent = out[\"sample\"][0] \n",
    "    masterpiece_latent_transition = out[\"latents\"]\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        masterpiece_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"pil\")[0]\n",
    "masterpiece_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imageio\n",
    "\n",
    "prompt = \"My soul transcends the ashes of my body to merge with the blissful, dimensionless void. Masterpiece by Anton Wiehe\"\n",
    "with autocast(\"cuda\"):\n",
    "    out = pipe(prompt, output_type=\"latent\", use_safety=False,\n",
    "                        num_inference_steps=50, guidance_scale=22.0, seed=0,\n",
    "                        width=512, height=512, start_img=None,\n",
    "                        )\n",
    "    masterpiece_latent = out[\"images\"][0] \n",
    "    \n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        masterpiece_image = pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"pil\")[0]\n",
    "    with torch.inference_mode():\n",
    "         masterpiece_torch= pipe.decode_image(masterpiece_latent.unsqueeze(0), output_type=\"torch\")\n",
    "masterpiece_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger. Stock photo. Flickr\", num_inference_steps=20, \n",
    "                    use_safety=False,\n",
    "                    guidance_scale=10, seed=0, start_img=None)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bernd_2 = \"Bernd the bread is a depressed loaf of pullman bread with hands.\"\n",
    "\n",
    "seeds = range(10)\n",
    "\n",
    "for seed in seeds:\n",
    "    with autocast(\"cuda\"):\n",
    "        image = pipe(prompt=bernd_2,\n",
    "                     num_inference_steps=30, \n",
    "                        use_safety=False,\n",
    "                        guidance_scale=15,\n",
    "\n",
    "                     seed=seed ** 3, start_img=None)[\"sample\"][0]\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = torch.load(\"/raid/8wiehe/tmp/ema_encodings.pt\")\n",
    "with autocast(\"cuda\"):\n",
    "    embed_image = pipe(text_embeddings=embeddings[0][0].cuda(),\n",
    "                 num_inference_steps=12, \n",
    "                    use_safety=False,\n",
    "                    guidance_scale=10, seed=1, start_img=None)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: how to to img2img with only very few steps???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Color consistency loss!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropyLoss(residual):\n",
    "   # residual.shape[0] -> batch size\n",
    "   # residual.shape[1] -> Number of channels\n",
    "   # residual.shape[2] -> Width\n",
    "   # residual.shape[3] -> Height\n",
    "    entropy = torch.zeros(residual.shape[0],1, requires_grad=False).cuda()\n",
    "    imageSize = float(residual.shape[1]*residual.shape[2]*residual.shape[3])\n",
    "    for i in range(0,residual.shape[0]): #loop over batch\n",
    "        res = residual[i].data.flatten(start_dim=0)# * 255)#.round()\n",
    "        _, counts=torch.unique(res , dim=0,return_counts=True) #flatt tensor and compute the unique values\n",
    "        p=(counts)/imageSize #compute the \n",
    "        entropy[i] = torch.sum(p* torch.log2(p))*-1\n",
    "    return entropy.mean()# counts\n",
    "# not differentiable! \n",
    "# torch.histc would be even better but is also not differentiable...\n",
    "grad_img = img_torch.float()\n",
    "grad_img.requires_grad = True\n",
    "\n",
    "entropyLoss(grad_img), entropyLoss(torch.rand_like(img_torch.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.histc(grad_img.flatten()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = entropyLoss(img_torch.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_entropy(input_tensor):\n",
    "    lsm = torch.nn.LogSoftmax()\n",
    "    log_probs = lsm(input_tensor)\n",
    "    probs = torch.exp(log_probs)\n",
    "    p_log_p = log_probs * probs\n",
    "    entropy = -p_log_p.mean()\n",
    "    return entropy\n",
    "calc_entropy(img_torch.float()), calc_entropy(torch.rand_like(img_torch.float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical, ContinuousBernoulli\n",
    "\n",
    "p_tensor = img_torch.float().squeeze().reshape(-1)\n",
    "m = ContinuousBernoulli(p_tensor)\n",
    "ent = m.entropy()\n",
    "print(ent.shape, ent.mean(), ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tensor = torch.tensor([0, 1])\n",
    "entropy2 = Categorical(probs = p_tensor).entropy()\n",
    "entropy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def spherical_dist_loss(x: torch.Tensor, y: torch.Tensor):\n",
    "    x = F.normalize(x, dim=-1)\n",
    "    y = F.normalize(y, dim=-1)\n",
    "    out = torch.norm(x - y, dim=-1)\n",
    "    out = torch.arcsin(out / 2)\n",
    "    out = (out ** 2) * 2\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_latents(latents, show=True):\n",
    "    latents = latents.cpu()\n",
    "    for channel in latents:\n",
    "        vals = channel.flatten()\n",
    "        plt.hist(vals.numpy(), bins=20)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    import io \n",
    "    from PIL import Image\n",
    "    with io.BytesIO() as img_buf:\n",
    "        plt.savefig(img_buf, format='png')\n",
    "        im = Image.open(img_buf)\n",
    "    return im\n",
    "\n",
    "def plot_color_hist(img):\n",
    "    fig, axs = plt.subplots(3, 1)\n",
    "    to_tens = T.ToTensor()\n",
    "    axs[0].hist(to_tens(img)[0].flatten().numpy().tolist(), bins=100, color=\"red\")\n",
    "    axs[1].hist(to_tens(img)[1].flatten().numpy().tolist(), bins=100, color=\"green\")\n",
    "    p = axs[2].hist(to_tens(img).flatten().numpy().tolist(), bins=100, color=\"blue\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: loss for differentiable histogram??\n",
    "\n",
    "# Loss for contrast should be checked! - does not seem to work or needs to be replaced with histogram-based loss\n",
    "\n",
    "# check if we can reduce contrast instead of doing match_histograms\n",
    "\n",
    "# can we adjust certain parameters based off histogram divergence? img2img strength?\n",
    "\n",
    "\n",
    "# carefully check stochastic encode of Defusion!!! \n",
    "#https://colab.research.google.com/github/deforum/stable-diffusion/blob/main/Deforum_Stable_Diffusion.ipynb#scrollTo=81qmVZbrm4uu\n",
    "# are we really doing the same!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_torch_img = True\n",
    "num_inference_steps = 22\n",
    "\n",
    "# callback params\n",
    "noise_strength_before_encode = 0.002\n",
    "lpips_lr = 0 # 150 leads to artefact\n",
    "lpips_frequency = 10 #10\n",
    "\n",
    "img2img_strength = 0.95 #  below 0.7 the background tends to converge to a uniform color\n",
    "\n",
    "contrast_lr = 10 #100\n",
    "normal_dist_lr = 0 #10 # 100 leads to grey\n",
    "match_histograms = 1\n",
    "\n",
    "# noise params\n",
    "num_points = 50\n",
    "num_noise = 10\n",
    "\n",
    "do_random_walk = False\n",
    "walk_strength = 3\n",
    "walk_barrier = 3\n",
    "walk_randomize = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if num_noise > 0 or do_random_walk:\n",
    "    if do_random_walk:\n",
    "        start_noise = pipe.sample_noise(512, 512).cpu()\n",
    "\n",
    "\n",
    "        noise_direction = torch.randn_like(start_noise) * walk_strength\n",
    "        noises = []\n",
    "        noise = start_noise\n",
    "        for i in range(num_points):\n",
    "            noise += noise_direction\n",
    "\n",
    "            # re-randomize\n",
    "            rerandomize_mask = torch.rand_like(noise) > walk_randomize\n",
    "            noise_direction[rerandomize_mask] = torch.randn_like(noise_direction[rerandomize_mask]) * walk_strength\n",
    "\n",
    "            # invert noise direction if abs val larger than walk_barrier and direction will make it larger\n",
    "            pos_inv_mask = (noise > walk_barrier) & (noise_direction > 0)\n",
    "            neg_inv_mask = (noise < -walk_barrier) & (noise_direction < 0)\n",
    "            inv_mask = pos_inv_mask | neg_inv_mask\n",
    "            noise_direction[inv_mask] *= -1\n",
    "\n",
    "            # norm noise\n",
    "            #noise = (noise - noise.mean()) / noise.std()\n",
    "            noises.append(noise.clone())\n",
    "\n",
    "    else:\n",
    "        # create noise\n",
    "        noises = [pipe.sample_noise(512, 512).cpu() for _ in range(num_noise)]\n",
    "        # makes sure mean is zero\n",
    "        noises = [n - n.mean() for n in noises]\n",
    "        # make sure their standard deviation is 1\n",
    "        noises = [n / n.std() for n in noises]\n",
    "        import sys\n",
    "        sys.path.append(\"../mus2vid\")\n",
    "        from mus2vid.math_utils import interp1d\n",
    "\n",
    "        if num_noise == 1:\n",
    "            noises = noises * num_points\n",
    "        elif num_noise == num_points:\n",
    "            noises = noises\n",
    "        else:\n",
    "            noises = interp1d(noises, num_points, use_slerp=1)\n",
    "\n",
    "\n",
    "    # makes sure mean is zero\n",
    "    noises = [n - n.mean() for n in noises]\n",
    "    # make sure their standard deviation is 1\n",
    "    noises = [n / n.std() for n in noises]\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot([n.std() for n in noises])\n",
    "    plt.ylim(0.5, 1.5)\n",
    "    plt.show()\n",
    "    plt.plot([n.mean() for n in noises])\n",
    "    plt.ylim(-0.5, .5)\n",
    "    plt.show()\n",
    "else:\n",
    "    noises = [None] * num_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spherical distance between noise points - ideally it is uniform\n",
    "dists = [spherical_dist_loss(noises[i].flatten(), noises[i+1].flatten()) for i in range(len(noises) - 1)]\n",
    "print(np.std(dists))\n",
    "plt.plot(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate spherical distance between noise points - ideally it is uniform\n",
    "dists = [spherical_dist_loss(noises[i].flatten(), noises[i+1].flatten()) for i in range(len(noises) - 1)]\n",
    "print(np.std(dists))\n",
    "plt.plot(dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "mapper = umap.UMAP(n_components=2)\n",
    "flat_noises = [n.flatten().cpu().numpy() for n in noises]\n",
    "labels = mapper.fit_transform(flat_noises)\n",
    "import umap.plot\n",
    "umap.plot.points(mapper, values=np.array(range(len(flat_noises))), theme=\"fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(img):\n",
    "    bs_img, c_img, h_img, w_img = img.size()\n",
    "    tv_h = torch.pow(img[:,:,1:,:]-img[:,:,:-1,:], 2).sum()\n",
    "    tv_w = torch.pow(img[:,:,:,1:]-img[:,:,:,:-1], 2).sum()\n",
    "    return (tv_h+tv_w) / (bs_img*c_img*h_img*w_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import skimage\n",
    "import cv2\n",
    "import torchvision\n",
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "from diffusers.callbacks import create_callbacks, ContrastLoss\n",
    "to_tensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "use_video_prompts = False\n",
    "\n",
    "\n",
    "imgs = [masterpiece_image]\n",
    "latents = [masterpiece_latent]\n",
    "latent_transition_list = []\n",
    "\n",
    "latent_cat_transitions = None\n",
    "image_cat = masterpiece_image\n",
    "img_torch = masterpiece_torch\n",
    "\n",
    "if use_video_prompts:\n",
    "    embeddings = torch.load(\"/raid/8wiehe/tmp/ema_encodings.pt\")\n",
    "    image_cat = None\n",
    "\n",
    "for i in range(30):\n",
    "    with autocast(\"cuda\"):\n",
    "        \n",
    "        if use_video_prompts:\n",
    "            embedding = embeddings[i][0].cuda()\n",
    "            prompt = None\n",
    "        else:\n",
    "            embedding = None\n",
    "            if i < 50:\n",
    "                prompt = \"A crow eating a burger. 4K nature photography\"\n",
    "                #prompt = \"Explosion of minds. Contest-winning photography by TJ Drysdale (4K)\"\n",
    "        \n",
    "            # prompt = \"Contest-winning artwork. Masterpiece\"\n",
    "        # zoom\n",
    "        import torchvision\n",
    "        #image_cat = torchvision.transforms.functional.affine(image_cat, angle=0, translate=(0.1, 0), shear=0, scale=0.8)\n",
    "        \n",
    "        if image_cat is None:\n",
    "            start_img = None\n",
    "        elif use_torch_img:\n",
    "            start_img = to_tensor(image_cat).cuda()\n",
    "        else:\n",
    "            start_img = image_cat\n",
    "        callbacks = create_callbacks(use_lpips=lpips_lr > 0, \n",
    "                                     lpips_image=start_img,\n",
    "                                     lpips_frequency=lpips_frequency,\n",
    "                                     lpips_lr=lpips_lr,\n",
    "                                     use_contrast=contrast_lr > 0,\n",
    "                                     contrast_lr=contrast_lr,\n",
    "                                     contrast_frequency=lpips_frequency,\n",
    "                                    use_normal_dist=normal_dist_lr > 0,\n",
    "                                    normal_dist_lr=normal_dist_lr,\n",
    "                                    )\n",
    "        \n",
    "        \n",
    "        from torchvision.transforms import ToPILImage\n",
    "        #start_img_pil = to_pil(start_img.cpu().squeeze())\n",
    "        #from skimage.filters import gaussian_filter\n",
    "        #start_img = gaussian_filter(start_img_pil, 2, multichannel=True, mode='reflect')\n",
    "        #start_img = cv2.GaussianBlur(np.array(start_img_pil), (33, 33), 2)\n",
    "        \n",
    "        out = pipe(prompt=prompt,#\"A cat eating a burger. Stock photo. Flickr\", \n",
    "                   text_embeddings=embedding,\n",
    "                       num_inference_steps=num_inference_steps, \n",
    "                       output_type=\"latent\",\n",
    "                        #latents=latent_cat_transitions[-90].cuda(),\n",
    "                        noise_strength_before_encode=noise_strength_before_encode, \n",
    "                        img2img_strength=img2img_strength, \n",
    "                        #noise_step=700, \n",
    "                        #t_start=15,\n",
    "                        #noise_strength=0.0,\n",
    "                        guidance_scale=10, \n",
    "                   seed=i * 100 + 3,\n",
    "                   start_img=start_img if img2img_strength > 0 else None,\n",
    "                   noise=noises[i].cuda() if noises[i] is not None else None,\n",
    "                   loss_callbacks=callbacks\n",
    "                  )\n",
    "        latent_cat = out[\"sample\"][0]\n",
    "        #latent_cat = latent_cat.clip(-4, 4)\n",
    "        #latent_cat_transitions = out[\"latents\"]\n",
    "        with torch.inference_mode():\n",
    "            image_cat = pipe.decode_image(latent_cat.unsqueeze(0), output_type=\"pil\")[0]\n",
    "        with torch.inference_mode():\n",
    "            img_torch = pipe.decode_image(latent_cat.unsqueeze(0), output_type=\"torch\")\n",
    "            \n",
    "        if match_histograms: \n",
    "            img_torch = maintain_colors(image_cat, masterpiece_image, hsv=0, lab=1, pil_input=1)\n",
    "            image_cat = to_pil(img_torch.squeeze())\n",
    "            \n",
    "            \n",
    "        print(i, latent_cat.min(), latent_cat.max(), latent_cat.mean(), latent_cat.std(), ContrastLoss()(img_torch))\n",
    "        print(\"TV loss: \", total_variation_loss(img_torch.float()))\n",
    "        #image_cat = to_pil(image_cat_tens.squeeze())\n",
    "    #image_cat.resize((256, 256), Image.LANCZOS).show()\n",
    "    image_cat.show()\n",
    "    plot_color_hist(image_cat)\n",
    "    imgs.append(image_cat)\n",
    "    latents.append(latent_cat)\n",
    "    #latent_transition_list.append(latent_cat_transitions)\n",
    "    \n",
    "# TODO: taking the latent from the optimization step before works! e.g. if we first train the initial start image for 50 steps, we can take the latent from step 20 of the process as the starting \n",
    "# latent for the new optimization. For the new optimization we set the inference steps to 30 and skip the first 12 steps. we can also  do 50 inference steps and skip the first 20 steps to get to the same result\n",
    "# no idea how to do this iteratively, as the second optimization only runs for 30 steps, so we cannot take the latent from the 30th latest step as it is the same one as before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = f\"{num_noise}_{num_points}_{lpips_lr}_{lpips_frequency}_{num_inference_steps}_{img2img_strength}_{contrast_lr}_{normal_dist_lr}_{do_random_walk}_{walk_strength}_{walk_barrier}_{walk_randomize}_{match_histograms}_{noise_strength_before_encode}_{prompt}.mp4\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "path = f'tmp/{name}.gif'\n",
    "if os.path.exists(path):\n",
    "    path = path.replace(\".gif\", \"_1.gif\")\n",
    "imageio.mimsave(path, [np.array(p) for p in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[1].save(\"something_is_wrong_with_my_burger.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "to_pil = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = maintain_colors(imgs[-1], imgs[-2], hsv=0, lab=1, pil_input=True)\n",
    "to_pil(out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax(a):\n",
    "    return (a - a.min()) / (a.max() - a.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens = maintain_colors(imgs[2], imgs[0], pil_input=True, lab=True).squeeze()\n",
    "tens_clipped = tens.float().clip(0, 1)\n",
    "pil_img = to_pil(tens_clipped)\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tens.max(), tens.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [l.cpu().abs().mean() for l in latents]\n",
    "plt.plot(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = [l.cpu().abs().std() for l in latents]\n",
    "plt.plot(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn(4, 64, 64).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latents(latents[0])\n",
    "plot_color_hist(imgs[0])\n",
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latents(latents[1])\n",
    "plot_color_hist(imgs[1])\n",
    "imgs[1].show()\n",
    "with torch.autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        pipe.decode_image(latents[1].unsqueeze(0).cuda().clip(-4, 4))[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latents(latents[2])\n",
    "plot_color_hist(imgs[2])\n",
    "imgs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latents(latents[-1])\n",
    "plot_color_hist(imgs[-1])\n",
    "imgs[-1].show()\n",
    "with torch.autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        pipe.decode_image(latents[-1].unsqueeze(0).cuda().clip(-4, 4))[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_color_hist(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(T.ToTensor()(imgs[idx])[0].flatten().numpy().tolist()) / 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plot_latents(latent_transition_list[0][0].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal optimization step 15 (start of other optimizations)\n",
    "out = plot_latents(latent_transition_list[0][14].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal optimization mid\n",
    "out = plot_latents(latent_transition_list[0][30].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal optimization end\n",
    "out = plot_latents(latent_transition_list[0][-1].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "out = plot_latents(latent_transition_list[1][-1].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plot_latents(latent_transition_list[2][0].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = plot_latents(latent_transition_list[-1][0].squeeze(), show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check sigmas of optimization for first run and others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: possiblity to get correct noise strength: use intermediate latents from last optimization run. Need to adjust num steps and sigmas (same num inference steps but increase t_start)\n",
    "# we should do that anyways for mtv to avoid the need to encode the old image to get the latent to be faster\n",
    "# TODO: CAREFUL, this does not work at all when applying transformations to the old image.... we need to encode the old image to get the correct latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show latent transtion for normal optimization\n",
    "plots = []\n",
    "for latents_of_trans in latent_transition_list[0]:\n",
    "    img = plot_latents(latents_of_trans.squeeze(), show=True)\n",
    "    plots.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(plots[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import os\n",
    "os.makedirs(\"tmp\", exist_ok=True)\n",
    "imageio.mimsave('./tmp/latent_transition.gif', [np.array(p) for p in plots])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "p = plt.hist(np.array(masterpiece_image)[:,:,0].flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "p = plt.hist(np.array(imgs[1])[:,:,0].flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "p = plt.hist(np.array(imgs[2])[:,:,0].flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_out = maintain_colors(imgs[1], imgs[2], pil_input=True, hsv=True)\n",
    "import torchvision\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "pil_img = to_pil(tensor_out.squeeze())\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "p = plt.hist(np.array(pil_img)[:,:,0].flatten(), bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_out = maintain_colors(imgs[1], imgs[0], pil_input=True, hsv=True)\n",
    "import torchvision\n",
    "to_pil = torchvision.transforms.ToPILImage()\n",
    "pil_img = to_pil(tensor_out.squeeze())\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_strength_before_encode=0.9, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()\n",
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                        noise_strength_before_encode=0.9, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]\n",
    "    image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_strength_before_encode=0.7, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()\n",
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                        noise_strength_before_encode=0.7, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]\n",
    "    image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_strength_before_encode=0.7, t_start=15, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()\n",
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                        noise_strength_before_encode=0.7, t_start=15, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]\n",
    "    image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A photo of a cat eating a burger. Realism\", num_inference_steps=50, \n",
    "                    img2img_strength=0.99, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A drunk duck attacks someone in a park\", num_inference_steps=50, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A photo of a duck that is attacking Donald Trump\", num_inference_steps=100, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=7.5, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A photo of a duck attacking Donald Trump in a park\", num_inference_steps=100, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=7.5, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A photo of a duck attacking Donald Trump in a park\", num_inference_steps=100, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=7.5, seed=0, start_img=None)[\"sample\"][0]\n",
    "image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A drunk duck is attacking Donald Trump. It looks very aggressive and Trump is hurt badly\", num_inference_steps=100, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=7.5, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A drunk duck is attacking Donald Trump. It looks very aggressive and Trump is hurt badly, num_inference_steps=50, \n",
    "                        img2img_strength=0.9, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]\n",
    "    image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.9, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image_cat.show()\n",
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                        img2img_strength=0.9, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]\n",
    "    image_cat.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.8, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterpiece_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"The machine elves are laughing at us\", num_inference_steps=50, \n",
    "                    img2img_strength=0.6, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"The machine elves are laughing at us\", num_inference_steps=50, \n",
    "                    img2img_strength=0.8, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.8, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.7, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.8, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.7, use_safety=False,\n",
    "image.show()\n",
    "for _ in range(10):\n",
    "    with autocast(\"cuda\"):\n",
    "        image_cat = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                        img2img_strength=0.7, use_safety=False,\n",
    "                        guidance_scale=6, seed=0, start_img=image_cat)[\"sample\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=10, \n",
    "                    img2img_strength=0.7, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.6, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.5, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    cat_image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.5, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    img2img_strength=0.3, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_step=937,\n",
    "                    t_start=3,\n",
    "                    use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=100, \n",
    "                    noise_strength=0.8,\n",
    "                    t_start=30,\n",
    "                    use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_step=200,\n",
    "                    t_start=40,\n",
    "                    use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_step=800,\n",
    "                    t_start=0,\n",
    "                    use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=50, \n",
    "                    noise_step=900,\n",
    "                    t_start=0,\n",
    "                    use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_strength = 0\n",
    "noise_step = 285\n",
    "img2img_strength = 0.0\n",
    "\n",
    "num_inference_steps = 50\n",
    "offset = 0\n",
    "batch_size = 1\n",
    "\n",
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        latents = pipe.encode_image(masterpiece_image)\n",
    "        # add noise\n",
    "        noise = torch.randn_like(latents, device=pipe.device)\n",
    "        if noise_strength is not None and noise_strength is not 0:\n",
    "            # old method to add noise:\n",
    "            noisy_latents = latents * (1 - noise_strength) + noise * noise_strength\n",
    "        elif noise_step is not None and noise_step > 0:\n",
    "            # now we use the scheduler to add noise\n",
    "            noisy_latents = pipe.scheduler.add_noise(latents, noise, noise_step)\n",
    "        elif img2img_strength is not None and img2img_strength is not 0:\n",
    "            init_timestep = int(num_inference_steps * img2img_strength) + offset\n",
    "            init_timestep = min(init_timestep, num_inference_steps)\n",
    "            print(\"init_timestep:\", init_timestep)\n",
    "            timesteps = int(pipe.scheduler.timesteps[-init_timestep])\n",
    "            timesteps = torch.tensor([timesteps] * batch_size, dtype=torch.long, device=pipe.device)\n",
    "            # add noise to latents using the timesteps\n",
    "            print(\"timesteps:\", timesteps)\n",
    "            noisy_latents = pipe.scheduler.add_noise(latents, noise, timesteps)\n",
    "        else: \n",
    "            noisy_latents = latents\n",
    "            \n",
    "        decoded = pipe.decode_image(noisy_latents)[0]\n",
    "decoded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        decoded = pipe.decode_image(latents)[0]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant = torch.quantile(latents.float().abs(), 0.9)\n",
    "print(quant)\n",
    "clipped_latent = torch.clip(latents, -quant, quant) #/ quant\n",
    "with autocast(\"cuda\"):\n",
    "    with torch.inference_mode():\n",
    "        decoded = pipe.decode_image(clipped_latent)[0]\n",
    "decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=30, \n",
    "                    noise_step=900, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=30, \n",
    "                    noise_step=950, use_safety=False,\n",
    "                    guidance_scale=6, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=30, \n",
    "                    noise_step=990, use_safety=False,\n",
    "                    guidance_scale=10, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger with its paws\", num_inference_steps=30, \n",
    "                    noise_step=990, use_safety=False,\n",
    "                    guidance_scale=10, seed=0, start_img=masterpiece_image)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast(\"cuda\"):\n",
    "    image = pipe(prompt=\"A cat eating a burger\", num_inference_steps=30, \n",
    "                    noise_step=999, use_safety=False, dynamic_thresholding_quant=0.0001,\n",
    "                    guidance_scale=6, seed=0, start_img=None)[\"sample\"][0]\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
